<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students 2025" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Sarcastic Arbitrage, Reflective Report, " />

<meta property="og:title" content="Silver Price Prediction: NLP Tool Comparison and Preliminary Sentiment Analysis "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/silver-price-prediction-nlp-tool-comparison-and-preliminary-sentiment-analysis.html" />
<meta property="og:description" content="By Group &#34;Sarcastic Arbitrage&#34; Codes and Blogs By [Yang Zhifu], [Qian Borui], [Tian Gesi], [Gao Jie], and [Li Yalun]. This is our Second Blog post detailing our NLP methodology, data cleaning process, and initial statistical results. 1. Introduction Our team, Sarcastic Arbitrage, focuses on exploring the relationship between sentiment within ‚Ä¶" />
<meta property="og:site_name" content="MFIN7036 Student Blog 2025" />
<meta property="og:article:author" content="MFIN7036 Students 2025" />
<meta property="og:article:published_time" content="2026-01-20T10:00:00+08:00" />
<meta name="twitter:title" content="Silver Price Prediction: NLP Tool Comparison and Preliminary Sentiment Analysis ">
<meta name="twitter:description" content="By Group &#34;Sarcastic Arbitrage&#34; Codes and Blogs By [Yang Zhifu], [Qian Borui], [Tian Gesi], [Gao Jie], and [Li Yalun]. This is our Second Blog post detailing our NLP methodology, data cleaning process, and initial statistical results. 1. Introduction Our team, Sarcastic Arbitrage, focuses on exploring the relationship between sentiment within ‚Ä¶">

        <title>Silver Price Prediction: NLP Tool Comparison and Preliminary Sentiment Analysis  ¬∑ MFIN7036 Student Blog 2025
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog 2025 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/"><span class=site-name>MFIN7036 Student Blog 2025</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2025-12
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/silver-price-prediction-nlp-tool-comparison-and-preliminary-sentiment-analysis.html">
                Silver Price Prediction: NLP Tool Comparison and Preliminary Sentiment Analysis
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group <em>"Sarcastic Arbitrage"</em></p>
<p style="font-size: 14px;">
  Codes and Blogs By
  <span style="font-weight: bold; font-style: italic;">[Yang Zhifu]</span>, 
  <span style="font-weight: bold; font-style: italic;">[Qian Borui]</span>, 
  <span style="font-weight: bold; font-style: italic;">[Tian Gesi]</span>, 
  <span style="font-weight: bold; font-style: italic;">[Gao Jie]</span>, 
  and
  <span style="font-weight: bold; font-style: italic;">[Li Yalun]</span>.
  This is our <span style="font-weight: bold; font-style: italic;">Second Blog </span> post detailing our NLP methodology, data cleaning process, and initial statistical results.
</p>

<h2>1. Introduction</h2>
<p>Our team, <strong>Sarcastic Arbitrage</strong>, focuses on exploring the relationship between sentiment within the Reddit community and silver price movements. </p>
<p>In our first blog post, we used a "RSS subscription + precision filtering" method to get relevant posts and comments from prominent subreddits including <code>r/PreciousMetals</code> and <code>r/Wallstreetsilver</code>. This was in reaction to Reddit's 2025 policy change, which closed self-service API access. We also got three months' worth of silver pricing data from Capital IQ, which we used as a starting point for further study.</p>
<p>In this blog, we go into more detail about the next steps in the process: 
1.  <strong>Data Cleaning:</strong> Getting rid of special characters, standardizing formats, and removing stop words.
2.  <strong>NLP Tool Comparison:</strong> We looked at three natural language processing (NLP) sentiment analysis tools (<strong>NLTK/VADER</strong>, <strong>FinBERT</strong>, and <strong>LLM like Qwen-Max</strong>) and compared them based on their core types, workflows, strengths, and weaknesses. 
3.  <strong>Statistical Results:</strong> We show results that come from comparing emotion scores with the logarithmic returns of silver prices.</p>
<h2>2. Data Cleaning</h2>
<p>To clean and gather the data, we imported Python libraries like <code>pandas</code> and <code>nltk</code>. Since our team is focusing on the sentiment of comments on social media (Reddit), the comments we scraped are usually quite different from financial news or reports, requiring deep cleaning.</p>
<h3>2.1. General Cleaning (Used for FinBERT &amp; LLM)</h3>
<p>For deep learning models like FinBERT and LLMs, we need to remove noise (like HTML tags and markdown) while preserving sentence structure and emojis, which often carry sentiment.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">html</span>

<span class="k">def</span> <span class="nf">clean_reddit_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deep cleaning of Reddit comment text for FinBERT/LLM</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>

    <span class="c1"># 1. HTML entity decoding</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">html</span><span class="o">.</span><span class="n">unescape</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># 2. Remove URLs and Reddit-specific markers</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;http\S+|www\.\S+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;/u/\w+|/r/\w+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># 3. Remove markdown formatting symbols (keep necessary punctuation)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\*\*|\*|~~|`&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># 4. Normalize whitespace</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">text</span>
</code></pre></div>

<h3>2.2. Stop Words Removal (Specific to NLTK)</h3>
<p>For the bag-of-words approach used in NLTK (and for generating WordClouds), we perform an extra step: removing "stop words" (common words like "the", "is", "at") that do not carry sentiment value.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="c1"># Download stop words list</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>

<span class="c1"># Remove stop words from text</span>
<span class="c1"># &#39;text&#39; is the column containing the lowercase comment</span>
<span class="n">comment_data</span><span class="p">[</span><span class="s1">&#39;text_clean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">comment_data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
                              <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">])))</span>
</code></pre></div>

<h2>3. Methodology: Why These 3 NLP Tools?</h2>
<p>As introduced, we adopted NLTK, FinBERT, and LLM for our sentiment analysis. We didn‚Äôt pick these tools at random‚Äîthey represent the three core paradigms of NLP sentiment analysis: <strong>rule-based</strong>, <strong>domain-specialized</strong>, and <strong>general-purpose LLMs</strong>. </p>
<p>Together, they cover our full workflow: from fast bulk screening to precise financial analysis and deep contextual interpretation. This layered approach ensures we never compromise on speed, accuracy, or nuance.</p>
<h3>3.1. NLTK (VADER): The Speed Demon for Bulk Screening</h3>
<p>VADER is a battle-tested rule-based lexicon tool built specifically for social media text. For our first step‚Äîsifting through tens of thousands of Reddit comments to separate signal from noise‚Äîit‚Äôs unbeatable. It acts as the ‚Äúworkhorse‚Äù that lets us quickly filter out low-value, neutral comments.</p>
<p><strong>Key Strengths:</strong>
*   <strong>Blazing fast throughput:</strong> Processes 10,000+ comments in seconds‚Äîcritical for handling Reddit‚Äôs high-volume discussions.
*   <strong>Zero cost &amp; zero setup:</strong> No training data or specialized hardware required; it works out of the box with a pre-built sentiment lexicon.
*   <strong>Intuitive output:</strong> Generates a compound score (-1 = extremely negative, 1 = extremely positive) plus clear positive/negative/neutral labels.</p>
<p><strong>Implementation Snippet:</strong>
Below is the core logic for initializing VADER and scoring a comment. It calculates a "compound" score which normalizes the sum of lexical ratings.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">nltk.sentiment.vader</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>

<span class="c1"># Initialize the VADER sentiment analyzer</span>
<span class="n">sid</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>

<span class="c1"># Example comment</span>
<span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;Silver to the moon! üöÄ Great time to buy.&quot;</span>

<span class="c1"># Obtain sentiment scores</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">comment</span><span class="p">)</span>

<span class="c1"># Output: {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.58, &#39;pos&#39;: 0.42, &#39;compound&#39;: 0.6588}</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sentiment Score: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;compound&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Critical Limitations:</strong>
*   <strong>Financial jargon blind:</strong> Relies on a general social media lexicon, so it can‚Äôt recognize terms like ‚ÄúSLV,‚Äù ‚ÄúETF,‚Äù or ‚Äúounce.‚Äù
*   <strong>Fails at sarcasm &amp; complex logic:</strong> Completely misses Reddit-style irony (e.g., ‚ÄúGreat, silver crashed again!‚Äù).</p>
<p><strong>Best For:</strong> Rapid initial screening of large datasets to filter out neutral comments.</p>
<h3>3.2. FinBERT: The Financial Expert for Precision Analysis</h3>
<p>Reddit‚Äôs silver discussions are packed with financial jargon like ‚ÄúSLV,‚Äù ‚ÄúETF,‚Äù and ‚ÄúFed rate hike.‚Äù Generic models flounder here, but FinBERT is a pre-trained BERT model fine-tuned on financial corpora (earnings calls, analyst reports). It ‚Äúspeaks the language‚Äù of traders.</p>
<p><strong>Key Strengths:</strong>
*   <strong>Unmatched financial accuracy:</strong> Outperforms generic models on terms like ‚Äúbearish,‚Äù ‚Äúrally,‚Äù and ‚Äústacking.‚Äù
*   <strong>Interpretable outputs:</strong> Provides probabilities for positive/negative/neutral labels, showing model confidence.
*   <strong>Efficient batch processing:</strong> Handles hundreds of comments at once, balancing speed and precision.</p>
<p><strong>Implementation Snippet:</strong>
We utilize the Hugging Face <code>transformers</code> pipeline to load the <code>ProsusAI/finbert</code> model. The following code demonstrates how we initialize the model and process a batch of text to get probability distributions.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="c1"># Initialize FinBERT model pipeline</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;ProsusAI/finbert&quot;</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span>  <span class="c1"># Return probabilities for all classes (positive, negative, neutral)</span>
<span class="p">)</span>

<span class="c1"># Example batch of comments</span>
<span class="n">batch</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Silver is going to crash, I&#39;m losing money.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Long term fundamentals look strong for precious metals.&quot;</span>
<span class="p">]</span>

<span class="c1"># Run inference</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

<span class="c1"># Process results to get the dominant label and score</span>
<span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="n">scores_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]:</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">res</span><span class="p">}</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores: </span><span class="si">{</span><span class="n">scores_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Critical Limitations:</strong>
*   <strong>Narrow domain focus:</strong> Struggles with non-financial slang or casual Reddit banter.
*   <strong>No context for irony:</strong> Still can‚Äôt parse sarcasm or counterfactual statements.</p>
<p><strong>Best For:</strong> Precision-focused analysis of professional financial discussions.</p>
<h3>3.3. LLM (e.g., Qwen-Max): The Context Detective for Nuanced Insights</h3>
<p>Reddit‚Äôs silver threads are full of slang (‚Äúapes,‚Äù ‚Äústacking‚Äù), sarcasm, and implicit market expectations. LLMs excel at understanding human-like language‚Äîthey‚Äôre the only option for digging into unspoken sentiment.</p>
<p><strong>Key Strengths:</strong>
*   <strong>Slang &amp; sarcasm decoder:</strong> Recognizes Reddit-specific lingo and ironic tone.
*   <strong>Structured, explainable outputs:</strong> With prompt engineering, we get structured JSON with sentiment labels and judgment rationales.
*   <strong>Universal adaptability:</strong> Handles almost any natural language edge case.</p>
<p><strong>Prompt Engineering Strategy:</strong></p>
<p>To ensure the LLM acts as a professional analyst rather than a generic chatbot, we employed a <strong>Structured Prompting</strong> strategy. We deliberately wrote the system prompt in <strong>Markdown</strong> format. </p>
<p><strong>Why Markdown?</strong> 
LLMs are heavily trained on code documentation and technical papers. Markdown syntax (like headers <code>##</code> and bullet points <code>-</code>) provides a clear logical hierarchy that the model understands natively. It helps the model distinguish between high-level instructions (Task) and specific constraints (Rules), reducing hallucination.</p>
<p><strong>Prompt Structure:</strong>
Our prompt follows a strict "Funnel Structure":
1.  <strong>Role Definition:</strong> Establishes the persona (Financial Market Analyst).
2.  <strong>Task Description:</strong> Defines the core objective clearly.
3.  <strong>Detailed Rules:</strong> Provides granular scoring criteria (-1.0 to +1.0) and probability requirements.
4.  <strong>Domain Adaptation:</strong> Explicitly maps Reddit slang (e.g., "diamond hands") to sentiment to bridge the cultural gap.
5.  <strong>Output Constraints:</strong> Enforces a strict JSON format for programmatic parsing.</p>
<p>Below is the actual System Prompt we designed:</p>
<div class="highlight"><pre><span></span><code>You are a professional financial market sentiment analyst specializing in analyzing discussions about precious metals (gold and silver) on social media platforms like Reddit.

## Task
Analyze the sentiment of user comments to determine their attitude toward precious metal price trends.

## Scoring Rules
### 1. Sentiment Classification (sentiment_label)
- **positive**: Bullish/Optimistic
- **negative**: Bearish/Pessimistic
- **neutral**: Neutral/Factual

### 2. Sentiment Intensity (sentiment_score)
Range: -1.0 to +1.0
- **+0.7 ~ +1.0**: Extremely bullish (e.g., &quot;all in silver! üöÄüöÄüöÄ&quot;)
- **-1.0 ~ -0.7**: Extremely bearish (e.g., &quot;Run! It&#39;s going to crash!&quot;)
... (intermediate ranges omitted for brevity)

## Special Processing Rules
1. **Emojis**: üöÄüíéüôå = extremely bullish; üìâüò≠üíî = extremely bearish
2. **Reddit Slang**:
   - &quot;to the moon&quot; / &quot;stonks&quot; ‚Üí positive
   - &quot;diamond hands&quot; ‚Üí positive (holding firm)
   - &quot;paper hands&quot; ‚Üí negative (selling easily)
   - &quot;bag holder&quot; ‚Üí negative (stuck with losses)

## Output Format (Strict JSON)
{
  &quot;sentiment_label&quot;: &quot;positive/negative/neutral&quot;,
  &quot;sentiment_score&quot;: 0.65,
  &quot;positive_prob&quot;: 0.75,
  &quot;negative_prob&quot;: 0.05,
  &quot;neutral_prob&quot;: 0.20,
  &quot;keywords&quot;: [&quot;bullish&quot;, &quot;buy&quot;, &quot;moon&quot;, &quot;üöÄ&quot;],
  &quot;reason&quot;: &quot;Brief explanation...&quot;
}
</code></pre></div>

<p><strong>Technical Optimization (Caching &amp; Concurrency):</strong>
Calling LLM APIs for thousands of comments is slow and expensive. To mitigate this, we implemented two key optimizations in our Python client:</p>
<ol>
<li><strong>Context Caching:</strong> Our System Prompt is long and complex. By enabling caching on the system message, the API (Qwen-Max) processes the prompt once and reuses the "kv-cache" for subsequent requests. This significantly reduces token consumption and latency.</li>
<li><strong>Concurrency:</strong> We use a <code>ThreadPoolExecutor</code> to send parallel requests, maximizing throughput without hitting API rate limits.</li>
</ol>
<p>Below is the implementation code using the <code>dashscope</code> SDK:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">dashscope</span>
<span class="kn">from</span> <span class="nn">http</span> <span class="kn">import</span> <span class="n">HTTPStatus</span>
<span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span><span class="p">,</span> <span class="n">as_completed</span>

<span class="c1"># Configure API Key</span>
<span class="n">dashscope</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;YOUR_DASHSCOPE_API_KEY&quot;</span>

<span class="k">class</span> <span class="nc">SentimentAnalysisClient</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span>

    <span class="k">def</span> <span class="nf">analyze_single_comment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">comment_text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls Qwen-Max with Context Caching enabled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">,</span>
                <span class="c1"># Enable caching for the heavy system prompt</span>
                <span class="c1"># Note: Check specific provider docs for exact cache syntax</span>
                <span class="s1">&#39;cache_control&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ephemeral&#39;</span><span class="p">}</span> 
            <span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">comment_text</span><span class="p">}</span>
        <span class="p">]</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">dashscope</span><span class="o">.</span><span class="n">Generation</span><span class="o">.</span><span class="n">call</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="s1">&#39;qwen-max&#39;</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
                <span class="n">result_format</span><span class="o">=</span><span class="s1">&#39;message&#39;</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="mf">0.2</span> 
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="n">HTTPStatus</span><span class="o">.</span><span class="n">OK</span><span class="p">:</span>
                <span class="n">content_str</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
                <span class="c1"># Clean code blocks if present</span>
                <span class="k">if</span> <span class="s2">&quot;```json&quot;</span> <span class="ow">in</span> <span class="n">content_str</span><span class="p">:</span>
                    <span class="n">content_str</span> <span class="o">=</span> <span class="n">content_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;```json&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;```&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">content_str</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;API Error: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">code</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">message</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parsing Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">run_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">comments_list</span><span class="p">,</span> <span class="n">max_workers</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processes comments in parallel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="n">max_workers</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
            <span class="n">future_to_comment</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">analyze_single_comment</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span> <span class="n">c</span> 
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">comments_list</span>
            <span class="p">}</span>

            <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">future_to_comment</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">data</span><span class="p">:</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

<p><strong>Critical Limitations:</strong>
*   <strong>High cost &amp; slow speed:</strong> Even with caching, inference takes seconds per comment compared to milliseconds for VADER.
*   <strong>Prompt-dependent:</strong> Output quality hinges on well-designed prompts; a vague prompt leads to vague analysis.
*   <strong>API rate limits:</strong> We must respect the provider's QPS (Queries Per Second) limits to avoid blocking.</p>
<p><strong>Best For:</strong> Where you need more than a score‚Äîyou need an explanation of <em>why</em> the model assigned that sentiment.</p>
<h2>4. Data Analysis and Preliminary Results</h2>
<p>So far, we have assigned a sentiment score to each comment we got from Reddit. In one day, there can be more than one comment about silver price, while on some other days, there are simply one comment or no comment on this topic. On the other hand, we have the daily silver price data (ideally, a much better academic study can collect minute-level price data and line up the data along each minute). Therefore, we should pack-up the sentiment scores within one day into a single number.</p>
<p>Two straightforward methods were applied, one is taking average and another is simply sum-up ‚Äî  this gives the idea of Average daily sentiment and Cumulative daily sentiment score.</p>
<p>The plotted results of NLTK, BERT, and LLM in average (left) and cumulative (right) daily scores are as followed:</p>
<div style="text-align: center;">
    <img src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/images/Sarcastic Arbitrage_02_image_AvgPlots.png" alt="Average Daily Sentiments" style="width: 90%; height: auto;">
</div>
<p><br></p>
<div style="text-align: center;">
    <img src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/images/Sarcastic Arbitrage_02_image_CumPlots.png" alt="Cumulative Daily Sentiments" style="width: 90%; height: auto;">
</div>
<p><br></p>
<p>From the two plots, we could visibly observe that Average Daily Sentiments works better than the Cumulative ones. Though not always leading the price surge, it generally fluctuates the same as the log return.</p>
<p>The MergeAvg and MergeCum refers to the arithmetic average of BERT, LLM and NLTK scores, which creates a combined score by three different NLP tools. The below plot shows clearly the performance of the merged sentiment scores ‚Äî  seems worse than the pure LLM. </p>
<div style="text-align: center;">
    <img src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/images/Sarcastic Arbitrage_02_image_CombinedSentiments.png" alt="Merged vs LLM Sentiment Plots" style="width: 90%; height: auto;">
</div>
<p><br></p>
<p>Below is the combination between Merged and pure LLM Daily average scores:</p>
<div style="text-align: center;">
    <img src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/images/Sarcastic Arbitrage_02_image_LLMvsMerged.png" alt="Detailed Comparison Plot" style="width: 90%; height: auto;">
</div>
<p><br></p>
<p>We can see, especially before January 2026, LLM scores successfully performed, sometimes (For example, between Nov 10 and Nov 17) can predict the price surge. On the other hand, at the beginning of January 2026, the price dived deeply and bounced back soon ‚Äî however, the Reddit users‚Äô emotions kept being negative and failed to predict the bounce.</p>
<h2>5. Conclusion and Future Work</h2>
<p>Our project has advanced research into the correlation between sentiment on Reddit and silver prices. Whilst the current association remains preliminary, our team has gained valuable technical, methodological, and practical experience throughout the research process ‚Äì from data collection and cleansing to NLP sentiment analysis and statistical validation.</p>
<p>Concurrently, we have formulated future research directions and optimisation plans:</p>
<ol>
<li><strong>Hybrid NLP Models:</strong> Advance the hybrid application of NLP models to combine the speed of VADER with the nuance of LLMs.</li>
<li><strong>Macroeconomic Data:</strong> Incorporate data such as inflation rates, interest rate changes, and industrial demand indicators into the research framework.</li>
<li><strong>Market Extension:</strong> Extend the current analytical framework to other precious metals (e.g., gold, platinum) and commodity markets (e.g., crude oil, copper).</li>
</ol>
<p>This work contributes both to academic understanding of commodity markets and provides practical reference for investors.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2026-01-20T10:00:00+08:00">Tue 20 January 2026</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/categories.html#reflective-report-ref">Reflective Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/tags.html#sarcastic-arbitrage-ref">Sarcastic Arbitrage
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2025-12" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-12/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>